{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always reload modules to have the current version\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranking.util import json_lines as jl\n",
    "from ranking.util import dataset_paths as dp\n",
    "from ranking.normalization import normalizer as n\n",
    "import pandas as pd\n",
    "\n",
    "input_file = ''\n",
    "cleaned_unique_functions_output  = 'complete-all-unique-functions.jsonl'\n",
    "tokenized_output = 'tok-' + cleaned_unique_functions_output\n",
    "lemmatized_output = 'lem-' + cleaned_unique_functions_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_extra_spaces(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def equalize_docItem(docItem):\n",
    "    no_empty_ctx = \"\".join(docItem.split('() =>'))\n",
    "    return strip_extra_spaces(no_empty_ctx)\n",
    "\n",
    "sign = '($$!) :: () => (i -> r) -> Number r i -> r'\n",
    "exptectedSign = '($$!) :: (i -> r) -> Number r i -> r'\n",
    "\n",
    "assert(equalize_docItem(sign) == exptectedSign)\n",
    "assert(exptectedSign == equalize_docItem(exptectedSign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds a storageId that acts a group id to each function\n",
    "def group_unique_functions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['equalizedDocItem'] = df.apply(\n",
    "        lambda row: equalize_docItem(row['docItem']), axis=1)\n",
    "    df['docContentLen'] = df['docContent'].str.len()\n",
    "    df.sort_values('docContentLen', ascending=False, inplace=True) # sort to have the longest documentation at the top position in each group\n",
    "    groups = df.groupby(['equalizedDocItem'])\n",
    "\n",
    "    df['storageId'] = groups.ngroup()\n",
    "    df['docContent'] = groups['docContent'].transform('first')\n",
    "    df['docItem'] = groups['docItem'].transform('first')\n",
    "    df['docType'] = groups['docType'].transform('first')\n",
    "    return df[['docId', 'storageId', 'docContent', 'docItem', 'docType', 'docPackage']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    groups = df.groupby('storageId')\n",
    "    df['docContent'] = groups['docContent'].transform('first').apply(lambda content: n.normalize(content, stop=n.get_wn_stopwords()))\n",
    "    return df\n",
    "\n",
    "def only_tokenize_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    groups = df.groupby('storageId')\n",
    "    df['docContent'] = groups['docContent'].transform('first').apply(lambda content: n.normalize(content, lambda text: text))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jl.read_jsonl(input_file)\n",
    "df['docContent'] = df['docContent'].apply(n.clean)\n",
    "df = df[df['docItem'] != '']  # ignore all items that are no functions\n",
    "df = group_unique_functions(df).sort_values('storageId')\n",
    "jl.to_jsonl(df, cleaned_unique_functions_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok = only_tokenize_dataset(df.copy())\n",
    "df_lem = normalize_dataset(df.copy())\n",
    "\n",
    "jl.to_jsonl(df_tok, tokenized_output)\n",
    "jl.to_jsonl(df_lem, lemmatized_output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b39dcb3d3362ff747ddce896d3961166e3de0f67646b9052166a268c283e04ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
